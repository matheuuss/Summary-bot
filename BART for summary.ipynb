{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f102dc6d",
   "metadata": {},
   "source": [
    "TO-DO\n",
    "1. Need to summarize only specific_docs, get doc_name for each summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ef7acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.6.7-py3-none-any.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<2.30.0 in /opt/anaconda3/lib/python3.9/site-packages (from llama-index) (2.28.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from llama-index) (1.21.5)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (from llama-index) (1.4.4)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp39-cp39-macosx_11_0_arm64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.7/761.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting langchain>=0.0.154\n",
      "  Downloading langchain-0.0.169-py3-none-any.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.7/823.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai>=0.26.4\n",
      "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index) (4.0.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index) (2.8.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index) (3.8.3)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.9/site-packages (from langchain>=0.0.154->llama-index) (1.4.39)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama-index) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<2.30.0->llama-index) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<2.30.0->llama-index) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<2.30.0->llama-index) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests<2.30.0->llama-index) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index) (2022.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama-index) (2022.7.9)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain>=0.0.154->llama-index) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (3.0.9)\n",
      "Installing collected packages: tenacity, pydantic, mypy-extensions, typing-inspect, tiktoken, openapi-schema-pydantic, marshmallow, openai, marshmallow-enum, dataclasses-json, langchain, llama-index\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed dataclasses-json-0.5.7 langchain-0.0.169 llama-index-0.6.7 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openai-0.27.6 openapi-schema-pydantic-1.2.4 pydantic-1.10.7 tenacity-8.2.2 tiktoken-0.4.0 typing-inspect-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index\n",
    "pip install PyPDF2\n",
    "pip install torch\n",
    "pip install transformers\n",
    "pip install accelerate\n",
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd05ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader('./example_document').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3d2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_text = []\n",
    "flag = 0\n",
    "for document in documents:             #only preprocess specific docs\n",
    "    single_document_text = []\n",
    "    for char in document.text:\n",
    "        if ord(char) < 32 or ord(char) > 127:\n",
    "            continue\n",
    "        else:\n",
    "            single_document_text.append(char)\n",
    "    single_document_text = ''.join(single_document_text)\n",
    "    documents_text.append(single_document_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdf752",
   "metadata": {},
   "source": [
    "1. Documents_text is an array of strings, where each string is text from a document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3c1bb",
   "metadata": {},
   "source": [
    "input_text = (\"Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959 ).\"\n",
    "\"Concerned with the development of algorithms which allow a computer to learn from the data and past experiences on their own .\"\n",
    "\"Learning is all about finding useful abstractions or concepts that describe the world .\"\n",
    "\n",
    "\"Syllabus for machine learning course is as follows\"\n",
    "\"Introduction to Machine Learning, Machine Learning Tools, Different types of Learning, Evaluation metrices and cross validation, Overfitting and underfitting, Supervised learning, Linear regression, Logistic regression, Decision Trees, Support Vector Machines, Artificial neural networks, Unsupervised learning, Semi -supervised learning, Introduction to deep learning ,Applications (image classification and segmentation)\" \n",
    "\n",
    "\"Teaching Assistants are  Siva Bonthada Poornanand Purushottam Naik\"\n",
    "\"Course Evaluation\"\n",
    "\"Mid Sem –20 %\"\n",
    "\"End Sem –40 %\"\n",
    "\"Viva -voce –20%\"\n",
    "\"Assignments / Course Project/ New ideas –20%\"\n",
    "\n",
    "\"AI and machine learning\"\n",
    "\"Al was introduced as an academic discipline in 1950s to create machines that can think.\"\n",
    "\"John McCarthy, widely recognized as one of the godfathers of AI, defined it as the science and engineering of making intelligent machines.\"\n",
    "\"Old-Fashioned AI were mainly based on rules .(eg.Chess -playing system) .\"\n",
    "\"Machine learning is a subset of AI.That is,all machine learning counts as AI,but not all AI counts as machine learning .\"\n",
    "\n",
    "\"Equation of a Tree ?\"\n",
    "\"We learned trees by looking at trees, not by studying its mathematical definition .In other words, we learned from data .\"\n",
    "\n",
    "\"Machine Learning History\"\n",
    "\"1943 - first mathematical model of neural networks presented in the scientific paper \\\"A logical calculus of the ideas immanent in nervous activity\\\" by Walter Pitts and Warren McCulloch .\"\n",
    "\"1949 : The book \\\"The Organization of Behavior\\\" by Donald Hebb is published.\"\n",
    "\"1950 : Arthur Samuel, a pioneer in machine learning, created a program for playing championship -level computer checkers .Arthur Samuel is the first person to come up with and popularize the term \\\"machine learning\\\" .\"\n",
    "\"1958 :  Frank Rosenblatt developed the perceptron. \"\n",
    "\"1967 -Thomas Cover and Peter E.Hart from Stanford publish an article in IEEE Transactions on Information Theory about the nearest neighbor algorithm.\"\n",
    "\"1970 :Modern version of BP(also called automatic differentiation) was first published by Finnish master student Seppo Linnainmaa.\"\n",
    "\"1979 -Japanese computer scientist Kunihiko Fukushima publishes his work on neo cognitron (the first CNN)\"\n",
    "\"1986 -Cognitive scientist Paul Smolensky comes up with a Restricted Boltzmann machine (RBM). \"\n",
    "\"1980 : Paper “The Strength of Weak Learnability” by Robert Schapire and Yoav Freund introduce “boosting” for machine learning.\"\n",
    "\"1995 -Random decision forests are introduced in a paper published by Tin Kam Ho.\"\n",
    "\"1998 :Yann LeCun and Yoshua Bengio Introduced the first CNN with backpropogation\"\n",
    "\"1995 -Corinna Cortes and Vladimir Vapnik publish their work on support -vector machines\"\n",
    "\"2009 -A massive visual database of labeled images ImageNet is launched by Fei -Fei Li.\"\n",
    "\"2010 - ReLU activation function popularized by Nair and Hinton, 2010\"\n",
    "\"2011 -Alex Krizhevsky et. al proposed AlexNet architecture\"\n",
    "\n",
    "\"Machine Learning Definition\"\n",
    "\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if itsperformance at tasks in T,as measured by P, improves with experience E (Tom Mitchell).\"\n",
    "\n",
    "\"A handwriting recognition learning problem:\" \n",
    "\"Task T: recognizing and classifying handwritten words within images\"\n",
    "\"Performance measure P: percent of words correctly classified\"\n",
    "\"Training experience E: a database of handwritten words with given classifications ComputerData Program OutputComputer\"\n",
    "\n",
    "\n",
    "\"Machine learning methods learns from data .\"\n",
    "\"Learning from data is used insituations where we don’t have an analytic solution ,but we do have data that we can use to construct an empirical solution .\"\n",
    "\"Learning from data is one of the most widely used techniques in science, engineering, and economics, among other fields.\"\n",
    "\"Machine learning is the science and art of programming computers so they can learn from data.\"\n",
    "\n",
    "\"Types of Learning\"\n",
    "\"Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input -output pairs. It infers a function from labeled training data consisting of a set of training examples .In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal ).\"\n",
    "\"Some important supervised learning methods\"\n",
    "\"Linear regression\"\n",
    "\"Logistic regression\"\n",
    "\"Support Vector Machines (SVM)\"\n",
    "\"Decision Trees and Random Forests\"\n",
    "\"Neural Networks\"\n",
    "\n",
    "\"Unsupervised Learning\"\n",
    "\"In the unsupervised setting, the training data does not contain any output information at all.\"\n",
    "\"In contrast to supervised learning, it’s not always easy to come up with metrics for how well an unsupervised learning algorithm is doing .\"\n",
    "\"Some important unsupervised learning methods\"\n",
    "\"Clustering\"\n",
    "\"Dimensionality reduction\"\n",
    "\"Reinforcement Learning\"\n",
    "\n",
    "\"In reinforcement learning,  the learning system, called an agent observe the environment, select and perform actions, and get rewards in return (or penalties in the form of negative rewards). \"\n",
    "\"It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation.\"\n",
    "\n",
    "\"Semi supervised Learning\"\n",
    "\"Some algorithms can deal with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data. This is called semi -supervised learning.\"\n",
    "\"Most semi -supervised learning algorithms are combinations of unsupervised and supervised algorithms.\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b741bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4415 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "input_text = documents_text[0]                                          #only give the specific documents index\n",
    "input_ids = tokenizer(input_text, return_tensors = 'pt')[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d00b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = 1\n",
    "total_size = input_ids.shape[1]\n",
    "chunk_size = total_size\n",
    "while chunk_size > 1024:\n",
    "    blocks += 1\n",
    "    chunk_size = total_size // blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b021d02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2af15859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1004\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n",
      "1003\n"
     ]
    }
   ],
   "source": [
    "remaining_tokens = total_size % blocks\n",
    "chunk_sizes = [chunk_size, chunk_size + 1]\n",
    "i = 0\n",
    "while(i < total_size):\n",
    "    if remaining_tokens:\n",
    "        curr_chunk_size = chunk_sizes[1]\n",
    "        remaining_tokens -= 1\n",
    "    else:\n",
    "        curr_chunk_size = chunk_sizes[0]\n",
    "    i += curr_chunk_size\n",
    "    #print(curr_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75813fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s><s>Cloud security audit issues and challenges. Livia Maria Brum  Economic Informatics Doctoral School The Bucharest University of Economic Studies Bucharest, Romania brumalivia@gmail.com  Abstract This paper analyzes the cyber security audit program of services, infrastructure and processes offered through the cloud.</s>\n",
      "</s><s>In practice, only limited forms of auditing may be performed by CSC administrators, and there exist a few compliance tools with several major limitation. Results obtained provide useful information for understanding and addressing the risks associated with cloud technologies. The simplest model to audit, from a CSC perspective, is the SaaS model because the responsibility of security is only for people and data.</s>\n",
      "</s><s>The use of audit logs may be deficient in a cloud environment compared to traditional IT, as this data may not be accessible to the organization. Existing methods for cloud audit are divided into three categories: retroactive, intercept-and-check and proactive auditing. There are multiple security solutions for auditing, developed by major cloud technology companies.</s>\n",
      "</s><s>ISACA proposes an audit / assurance program based on 3 steps - planning and scoping the audit, governing the cloud and operating in the cloud. The rapid evolution of cloud technologies determines the achievement of standards applicable to all CSPs in order to provide a degree of trust to users.</s>\n",
      "</s><s>The security audit process is necessary and provides objective feedback on the security status of the organization. The cloud security audit differs from the one performed on traditional technologies due to the characteristics of the cloud. It is necessary to identify new methods that can respond to the specific elements of thecloud in order to carry out an audit.</s>\n"
     ]
    }
   ],
   "source": [
    "remaining_tokens = total_size % blocks\n",
    "chunk_sizes = [chunk_size, chunk_size + 1]\n",
    "i = 0\n",
    "while(i < total_size):\n",
    "    if remaining_tokens:\n",
    "        curr_chunk_size = chunk_sizes[1]\n",
    "        remaining_tokens -= 1\n",
    "    else:\n",
    "        curr_chunk_size = chunk_sizes[0]\n",
    "    outputs = model.generate(input_ids[:, i:i+curr_chunk_size])         #write which point belongs to which document,for that I'll have to pass each document seperately\n",
    "    print(tokenizer.decode(outputs[0]))\n",
    "    i += curr_chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6354481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0,  1121, 37700,  2239,     6,  1437,     5,  2239,   467,\n",
       "             6,   373,    41,  2936, 14095,     5,  1737,     6,  5163,     8,\n",
       "          3008,  2163,     6,     8,   120, 12840,    11,   671,     4,    85,\n",
       "           531,   172,  1532,    30,  1495,    99,    16,     5,   275,  1860,\n",
       "             6,   373,    10,   714,     6,     7,   120,     5,   144,  7970,\n",
       "            81,    86,     4,    83,   714, 19857,    99,   814,     5,  2936,\n",
       "           197,  2807,    77,    24,    16,    11,    10,   576,  1068,     4,\n",
       "             2]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
